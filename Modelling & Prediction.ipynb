{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rpt1gcg6dfkr"
   },
   "source": [
    "# 데이터 적재 및 모델 구축에 필요한 함수 정의, 모듈 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 598
    },
    "executionInfo": {
     "elapsed": 8213,
     "status": "ok",
     "timestamp": 1601085724291,
     "user": {
      "displayName": "Namo Bang",
      "photoUrl": "",
      "userId": "10443031996793889049"
     },
     "user_tz": -540
    },
    "id": "SPB6eCi4GjuR",
    "outputId": "6255989c-991c-42a9-afe9-e394ef1021db"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime as dt\n",
    "import math\n",
    "import copy\n",
    "import re\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#import tensorflow as tf\n",
    "#from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.base import clone\n",
    "#import konlpy\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 695,
     "status": "ok",
     "timestamp": 1601082382216,
     "user": {
      "displayName": "Namo Bang",
      "photoUrl": "",
      "userId": "10443031996793889049"
     },
     "user_tz": -540
    },
    "id": "SvT5L_zhlnhy"
   },
   "outputs": [],
   "source": [
    "def MAPE(y_test, y_pred):\n",
    "    return np.mean(np.abs((y_test - y_pred) / y_test)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 497,
     "status": "ok",
     "timestamp": 1601082384855,
     "user": {
      "displayName": "Namo Bang",
      "photoUrl": "",
      "userId": "10443031996793889049"
     },
     "user_tz": -540
    },
    "id": "jCV68-CLizar"
   },
   "outputs": [],
   "source": [
    "def drop_col_feat_imp(model, X_train, y_train, random_state=42):\n",
    "    '''\n",
    "    구동 원리:\n",
    "    1. 모든 변수 (feature) 를 피처로 사용했을 때의 R2-Score 계산\n",
    "    2. 변수 한 개씩을 제외하며 R2-Score 기준으로 성능 확인\n",
    "    3. ((전체 변수 이용했을 때의 R2-Score) - (변수 1개를 제외했을 때의 R2-Score)) 값 계산\n",
    "    4. 3번 값이 음수라면 해당 변수를 제거하는 편이 좋다고 판단, 양수라면 해당 변수가 포함되어 있는 편이 좋다고 결론\n",
    "    '''\n",
    "\n",
    "    model_clone = clone(model)\n",
    "    model_clone.random_state = random_state\n",
    "    model_clone.fit(X_train, y_train)\n",
    "    benchmark_score = model_clone.score(X_train, y_train)\n",
    "\n",
    "    importances = []\n",
    "    n_iter = 1\n",
    "    for col in X_train.columns:\n",
    "        print('iteration: {}'.format(n_iter))\n",
    "        model_clone = clone(model)\n",
    "        model_clone.random_state = random_state\n",
    "        model_clone.fit(X_train.drop(col, axis=1), y_train)\n",
    "        drop_col_score = model_clone.score(X_train.drop(col, axis=1), y_train)\n",
    "        importances.append(benchmark_score - drop_col_score)\n",
    "        n_iter += 1\n",
    "        clear_output()\n",
    "\n",
    "    dic = {'feature': X_train.columns, 'importances': importances}\n",
    "    importances_df = pd.DataFrame(dic)\n",
    "\n",
    "    return importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "FtKs0T3fI37t"
   },
   "outputs": [],
   "source": [
    "def Jaccard_similarity(doc1, doc2):\n",
    "    doc1 = set(doc1)\n",
    "    doc2 = set(doc2)\n",
    "    return len(doc1 & doc2) / len(doc1 | doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 659,
     "status": "ok",
     "timestamp": 1601082499222,
     "user": {
      "displayName": "Namo Bang",
      "photoUrl": "",
      "userId": "10443031996793889049"
     },
     "user_tz": -540
    },
    "id": "-RLa5z6cpeGs"
   },
   "outputs": [],
   "source": [
    "def intersection_similarity(doc1, doc2):\n",
    "    '''\n",
    "    2개의 상품명을 비교하여 공통적으로 존재하는 단어 수 반환 (교집합 기반) \n",
    "    '''\n",
    "    doc1 = set(doc1)\n",
    "    doc2 = set(doc2)\n",
    "    return len(doc1 & doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inter_info_ratio(doc1,doc2):\n",
    "    '''\n",
    "    (두 개의 상품명 doc1, doc2 을 비교하여 공통적으로 존재하는 단어 수 / 하나의 상품명 (doc1) 의 단어 수) 계산\n",
    "    -> '공통 정보 비율' 값을 도출\n",
    "    '''\n",
    "    return intersection_similarity(doc1,doc2)/len(set(doc1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 1792,
     "status": "ok",
     "timestamp": 1601085122256,
     "user": {
      "displayName": "Namo Bang",
      "photoUrl": "",
      "userId": "10443031996793889049"
     },
     "user_tz": -540
    },
    "id": "nGy9JouLKjkn"
   },
   "outputs": [],
   "source": [
    "# 상품의 유사도를 기반으로 과거 실적을 매핑하기 위해 정의한 클래스\n",
    "\n",
    "class MapPastPred():\n",
    "\n",
    "    def __init__(self, df2019, df2020):\n",
    "\n",
    "        self.df2019_items = np.unique(df2019.상품코드.values)\n",
    "        self.df2019_mother = np.unique(df2019.마더코드.values)\n",
    "        self.df2019 = df2019\n",
    "        self.df2020 = df2020\n",
    "\n",
    "    def mapping(self, option='name'): # 2019년도에 판매된 상품 - 2020년도 6월에 판매된 상품을 유사한 것들끼리 상품코드 기준으로 매핑\n",
    "        df = pd.DataFrame()\n",
    "        상품2020 = []\n",
    "        상품2019 = []\n",
    "        iir=[]\n",
    "        noise = []\n",
    "        item2019 = self.df2019[['상품코드', '상품명', '마더코드', '판매단가', '상품군']]\n",
    "        item2019 = item2019.drop_duplicates('상품코드')\n",
    "        elimination = '[(초특가)(\\(.+\\))(무이자)(세트)(1+1)(일시불)(\\[.+\\])(\\d+종)(\\d+팩)(\\+)(\\-)]'\n",
    "        item2019['상품명'] = [re.sub(elimination, '', i)\n",
    "                           for i in item2019.상품명]\n",
    "\n",
    "        season = np.unique(self.df2019[(\n",
    "            self.df2019.방송일시 >= '2019-05-01') & (self.df2019.방송일시 < '2019-09-01')].상품코드.values)\n",
    "        season_cat = ['의류', '가전', '농수축']\n",
    "\n",
    "        tag = konlpy.tag.Kkma()\n",
    "        item2019['토큰'] = [tag.nouns(i) for i in item2019.상품명]\n",
    "\n",
    "        for i in np.unique(self.df2020.상품코드.values):\n",
    "            if i in self.df2019_items:\n",
    "                상품2020.append(i)\n",
    "                상품2019.append(i)\n",
    "                name_token = item2019[item2019.상품코드 == i].토큰.values[0]\n",
    "                iir.append(len(name_token))\n",
    "            else:\n",
    "                상품2020.append(i)\n",
    "\n",
    "                similarity = pd.DataFrame()\n",
    "                mother = self.df2020[self.df2020.상품코드 == i].마더코드.values[0]\n",
    "                cat = self.df2020[self.df2020.상품코드 == i].상품군.values[0]\n",
    "                price = self.df2020[self.df2020.상품코드 == i].판매단가.values[0]\n",
    "\n",
    "                if mother in self.df2019_mother:\n",
    "                    temp = item2019[item2019.마더코드 == mother][[\n",
    "                        '상품코드', '상품명', '토큰', '판매단가']]\n",
    "\n",
    "                    if len(temp) == 0:\n",
    "                        temp = item2019[item2019.상품군 == cat][[\n",
    "                            '상품코드', '상품명', '토큰', '판매단가']]\n",
    "                        if self.df2020[self.df2020.상품코드 == i].상품군.values[0] in season_cat:\n",
    "                            temp = temp[temp.상품코드.isin(season)]\n",
    "\n",
    "                else:\n",
    "                    temp = item2019[item2019.상품군 == cat][[\n",
    "                        '상품코드', '상품명', '토큰', '판매단가']]\n",
    "                    if self.df2020[self.df2020.상품코드 == i].상품군.values[0] in season_cat:\n",
    "                        temp = temp[temp.상품코드.isin(season)]\n",
    "\n",
    "                temp_sub = temp.copy()\n",
    "                temp = temp[(temp.판매단가 > price*0.7) & (temp.판매단가 < price*1.3)]\n",
    "\n",
    "                if len(temp) == 0:\n",
    "                    temp = temp_sub\n",
    "\n",
    "                temp.drop_duplicates('상품명', keep='first', inplace=True)\n",
    "\n",
    "                if option == 'name':\n",
    "                    code = []\n",
    "                    similar = []\n",
    "\n",
    "                    name = self.df2020[self.df2020.상품코드 == i].상품명.values[0]\n",
    "                    name = re.sub(elimination, '', name)\n",
    "                    token = tag.nouns(name)\n",
    "\n",
    "                    for k in range(len(temp)):\n",
    "                        code.append(temp.상품코드.values[k])\n",
    "                        similar.append(intersection_similarity(token, temp.토큰.values[k]))\n",
    "\n",
    "                    similarity['상품코드'] = code\n",
    "                    similarity['유사도'] = similar\n",
    "                    similarity = similarity.sort_values(\n",
    "                        '유사도', ascending=False).reset_index(drop=True)\n",
    "                    iir.append(max(similar))\n",
    "                    noise.append(1)\n",
    "\n",
    "                    if len(similarity) > 1:\n",
    "\n",
    "                        if len(similarity[similarity.유사도 == max(similarity.유사도.values)]) > 1:\n",
    "                            temp2 = similarity[similarity.유사도 == max(\n",
    "                                similarity.유사도.values)]\n",
    "                            temp2 = temp2.merge(\n",
    "                                temp[['상품코드', '판매단가']], on='상품코드', how='left')\n",
    "                            temp2['가격차이'] = (\n",
    "                                temp['판매단가'] - self.df2020[self.df2020.상품코드 == i].판매단가.values[0]).apply(np.abs)\n",
    "                            temp2 = temp2.sort_values(\n",
    "                                '가격차이').reset_index(drop=True)\n",
    "                            상품2019.append(temp2.상품코드.values[0])\n",
    "\n",
    "                        else:\n",
    "                            상품2019.append(similarity.상품코드.values[0])\n",
    "\n",
    "                    else:\n",
    "                        상품2019.append(similarity.상품코드.values[0])\n",
    "\n",
    "                elif option == 'onlyprice':\n",
    "                    temp['판매단가'] = (temp.판매단가 - price).apply(np.abs)\n",
    "                    temp = temp.sort_values('판매단가')\n",
    "                    상품2019.append(temp.상품코드.values[0])\n",
    "\n",
    "        df['pred상품코드'] = 상품2020\n",
    "        df['past상품코드'] = 상품2019\n",
    "        df['공통정보량'] = iir\n",
    "\n",
    "        self.mapping_table = df\n",
    "        return df\n",
    "\n",
    "    def mapping_transform(self, option='name'): # 상품코드 기준으로 과거실적 매핑\n",
    "        mapped_table = self.mapping(option=option)\n",
    "        df2020 = self.df2020.copy()\n",
    "        df2019 = self.df2019.copy()\n",
    "\n",
    "        past_performance = df2019.pivot_table(index='상품코드', values='취급액',\n",
    "                                              aggfunc='mean')\n",
    "        past_performance.reset_index(inplace=True)\n",
    "        past_performance.columns = ['상품코드', '과거실적']\n",
    "\n",
    "        transformed_table = pd.merge(mapped_table, past_performance, left_on='past상품코드',\n",
    "                                     right_on='상품코드', how='left')\n",
    "        transformed_table = transformed_table[['pred상품코드','공통정보량', '과거실적']]\n",
    "\n",
    "        df2020 = pd.merge(df2020, transformed_table, left_on='상품코드', right_on='pred상품코드',\n",
    "                          how='left')\n",
    "\n",
    "        del df2020['pred상품코드']\n",
    "        \n",
    "        \n",
    "        for i in df2020.loc[df2020.공통정보량==0].index:\n",
    "            cate = df2020.loc[i,'상품군']\n",
    "            price = df2020.loc[i,'판매단가']\n",
    "            df2020.loc[i,'과거실적'] = df2019[(df2019.상품군 == cate)&\\\n",
    "                                          (df2019.판매단가>price*0.7)&\\\n",
    "                                          (df2019.판매단가<price*1.3)].취급액.mean()\n",
    "            \n",
    "        self.mapping_transform_table = df2020\n",
    "        return df2020\n",
    "    \n",
    "def mean_performance(df): # 상품 코드 별 취급액 평균 계산\n",
    "    past_performance = df.pivot_table(index='상품코드', values='취급액', aggfunc='mean')\n",
    "    past_performance.reset_index(inplace=True)\n",
    "    past_performance.columns = ['상품코드', '과거실적']\n",
    "    df1 = pd.merge(df, past_performance, on='상품코드', how='left')\n",
    "    return df1\n",
    "    \n",
    "def noise_making(df2019,ratio=0.3):\n",
    "    '''\n",
    "    과거 판매 이력이 없는 상품이 많은 상황을 가정하여 몇 개 상품의 실적을 의도적으로 가리고,\n",
    "    매핑 다른 상품코드의 과거실적을 대신 매핑하는 방식으로 학습 데이터 재구축\n",
    "    '''\n",
    "    df = df2019.copy()\n",
    "    item = list(np.unique(df.상품코드))\n",
    "    random.shuffle(item)\n",
    "    idx = int(len(item)*ratio)\n",
    "    noise_item = item[:idx]\n",
    "    normal_item = item[idx:]\n",
    "    \n",
    "    normal = df[df.상품코드.isin(normal_item)]\n",
    "    noise = df[df.상품코드.isin(noise_item)]\n",
    "    \n",
    "    mapp = MapPastPred(normal,noise)\n",
    "    table = mapp.mapping_transform(option='name')\n",
    "    \n",
    "    df['공통정보량'] = 1\n",
    "    df = mean_performance(df)\n",
    "    \n",
    "    noise_table = pd.concat([df,table])\n",
    "    noise_table.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    return {'noise_table':noise_table,'only_normal':df,'only_noise':table}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PNuhrJDKHqtT"
   },
   "source": [
    "# StackingModel을 생성하는 Class 선언 및 예측, 저장\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3GoVWc4cZl1z"
   },
   "source": [
    "## StackingModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(7777)\n",
    "np.random.seed(7777)\n",
    "random.seed(7777)\n",
    "class StackingRegressor():\n",
    "    def __init__(self,\n",
    "                 model1=CatBoostRegressor(verbose=False,\n",
    "                                               loss_function='MAE',\n",
    "                                               random_state=7777,\n",
    "                                               bagging_temperature=3,\n",
    "                                               depth=8,\n",
    "                                               learning_rate=0.1),\n",
    "                 model2=tf.keras.models.Sequential([\n",
    "                     tf.keras.layers.Flatten(),\n",
    "                     tf.keras.layers.Dense(180, activation='relu'),\n",
    "                     tf.keras.layers.Dense(360, activation='relu'),\n",
    "                     tf.keras.layers.Dropout(0.3,seed=7777),\n",
    "                     tf.keras.layers.Dense(720, activation='relu'),\n",
    "                     tf.keras.layers.Dense(180, activation='relu'),\n",
    "                     tf.keras.layers.Dense(90, activation='relu'),\n",
    "                     tf.keras.layers.Dense(1)\n",
    "                 ])):\n",
    "        \n",
    "        self.model1 = model1\n",
    "        self.model2 = model2\n",
    "        model2.compile(optimizer='adam', loss='mape', metrics=['mae', 'mse'])\n",
    "\n",
    "    def fit(self, train_set, target_col='취급액'):\n",
    "\n",
    "        self.target_col = target_col\n",
    "        self.train = train_set\n",
    "\n",
    "        feature_col = [\n",
    "            '상품군', '판매단가', '월', '요일', '시', '분', '주말', '공휴일', '지불방식', '노출분',\n",
    "            '누적노출', '마감시간여부', '계절_numeric', '일평균기온', '일최저기온', '일최고기온', '일별강수량',\n",
    "            '태풍발생', '일별상대습도', '일평균풍속', '홈쇼핑검색량', 'NS검색량', '클릭비율', '과거실적'\n",
    "        ]\n",
    "\n",
    "        self.cat_feature = [\n",
    "            '과거실적', '시', '판매단가', '마감시간여부', '누적노출', '분', '상품군', '클릭비율', '요일',\n",
    "            '홈쇼핑검색량', '공휴일', '일평균풍속', '주말', '계절_numeric', 'NS검색량', '태풍발생',\n",
    "            '노출분', '일평균기온', '일별강수량', '월', '일별상대습도', '일최저기온', '지불방식', '일최고기온'\n",
    "        ]\n",
    "\n",
    "        self.feature_not_col = [\n",
    "            '방송일시', '노출(분)', '마더코드', '상품코드', '상품명', '취급액', '년', '일', '방송날짜',\n",
    "            '계절_categoric'\n",
    "        ]\n",
    "\n",
    "        cate = np.unique(self.train.상품군.values)\n",
    "        self.replace_ = {cate[i]: i for i in range(len(cate))}\n",
    "\n",
    "        train = mean_performance(self.train)\n",
    "\n",
    "        X_train = train[self.cat_feature]\n",
    "        y_train = train[self.target_col]\n",
    "        X_train.상품군 = X_train.상품군.replace(self.replace_)\n",
    "\n",
    "        self.model1.fit(X_train, y_train)\n",
    "        self.cat_pred = self.model1.predict(X_train)\n",
    "        \n",
    "        dnn_train = self.train.copy()\n",
    "        categorical = ['상품군','월', '요일', '시', '분', '주말', '지불방식', '계절_numeric', '태풍발생']\n",
    "        one_hot = pd.get_dummies(dnn_train, columns=categorical)\n",
    "        train = mean_performance(one_hot)\n",
    "        \n",
    "        feature_not_col = [\n",
    "            '방송일시', '노출(분)', '마더코드', '상품코드', '상품명', '취급액', '년', '일', '방송날짜',\n",
    "            '계절_categoric'\n",
    "        ]\n",
    "        \n",
    "        X_train = train.drop(feature_not_col, axis=1)\n",
    "        y_train = train['취급액']\n",
    "        \n",
    "        X_train['cat_pred'] = self.cat_pred\n",
    "        self.feature_ = X_train.columns\n",
    "        \n",
    "        \n",
    "        self.dnn_train = X_train\n",
    "\n",
    "        with tf.device(\"/device:CPU:0\"):\n",
    "            self.model2.fit(X_train.values,\n",
    "                        y_train.values,\n",
    "                        epochs=10,\n",
    "                        batch_size=30)\n",
    "\n",
    "    def predict(self, test_set):\n",
    "\n",
    "        self.test = test_set\n",
    "\n",
    "        mapping_ = MapPastPred(self.train, self.test)\n",
    "        cat_val = mapping_.mapping_transform()\n",
    "\n",
    "        X_test = cat_val[self.cat_feature]\n",
    "        self.y_test = cat_val[self.target_col]\n",
    "\n",
    "        X_test.상품군 = X_test.상품군.replace(self.replace_)\n",
    "        X_test = X_test[self.cat_feature]\n",
    "\n",
    "        self.cat_y_pred = self.model1.predict(X_test)\n",
    "        \n",
    "        #colums 수 맞추는 작업\n",
    "        dnn_train = self.train.copy()\n",
    "        dnn_val = self.test.copy()\n",
    "\n",
    "        dnn_train['구분'] = 'train'\n",
    "        dnn_val['구분'] = 'val'\n",
    "\n",
    "        all_table = pd.concat([dnn_train, dnn_val])\n",
    "        categorical = ['월', '요일', '시', '분', '주말', '지불방식', '계절_numeric', '태풍발생']\n",
    "        one_hot = pd.get_dummies(all_table, columns=categorical)\n",
    "\n",
    "        dnn_train = one_hot[one_hot.구분 == 'train']\n",
    "        dnn_val = one_hot[one_hot.구분 == 'val']\n",
    "\n",
    "        mapp = MapPastPred(dnn_train, dnn_val)\n",
    "        val = mapp.mapping_transform()\n",
    "\n",
    "        del val['공통정보량']\n",
    "\n",
    "        train = mean_performance(dnn_train)\n",
    "\n",
    "        feature_not_col = [\n",
    "            '방송일시', '노출(분)', '마더코드', '상품코드', '상품명', '취급액', '년', '일', '방송날짜',\n",
    "            '계절_categoric'\n",
    "        ]\n",
    "\n",
    "        dt = pd.concat([train, val])\n",
    "        dt = pd.get_dummies(dt, columns=['상품군'])\n",
    "        dnn_train = dt[dt.구분 == 'train']\n",
    "        dnn_val = dt[dt.구분 == 'val']\n",
    "\n",
    "        del dnn_val['구분']\n",
    "        \n",
    "\n",
    "        X_test = dnn_val.drop(feature_not_col, axis=1)\n",
    "        \n",
    "        X_test['cat_pred'] = self.cat_y_pred\n",
    "        X_test=X_test[self.feature_]\n",
    "        \n",
    "        self.dnn_test = X_test\n",
    "        \n",
    "        with tf.device(\"/device:CPU:0\"):\n",
    "            self.predict_ = self.model2.predict(X_test.values)\n",
    "\n",
    "        self.score = MAPE(self.y_test, self.predict_.reshape(-1))\n",
    "\n",
    "        return self.predict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,val = pd.read_excel('../data/internal/preprocessed_data/train_data/실적_전처리.xlsx'),pd.read_excel('../data/internal/preprocessed_data/test_data/평가_전처리.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위의 데이터 임포트 코드 실행 순서가 2인 것에 대한 설명: 본 코드 파일을 제출용 폴더에 옮긴 후에도 데이터 적재가 잘 되는지 마지막으로 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stack_ = StackingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35379 samples\n",
      "Epoch 1/10\n",
      "35379/35379 [==============================] - 5s 128us/sample - loss: 23.6718 - mae: 4293732.0000 - mse: 53948295675904.0000\n",
      "Epoch 2/10\n",
      "35379/35379 [==============================] - 3s 87us/sample - loss: 22.4323 - mae: 4068617.7500 - mse: 48482790408192.0000\n",
      "Epoch 3/10\n",
      "35379/35379 [==============================] - 3s 91us/sample - loss: 22.3016 - mae: 4021020.5000 - mse: 47138520170496.0000\n",
      "Epoch 4/10\n",
      "35379/35379 [==============================] - 3s 93us/sample - loss: 22.1578 - mae: 3990498.0000 - mse: 47261589438464.0000\n",
      "Epoch 5/10\n",
      "35379/35379 [==============================] - 4s 99us/sample - loss: 22.1802 - mae: 4009853.7500 - mse: 47597913899008.0000\n",
      "Epoch 6/10\n",
      "35379/35379 [==============================] - 3s 89us/sample - loss: 22.2021 - mae: 4006333.7500 - mse: 47405672169472.0000\n",
      "Epoch 7/10\n",
      "35379/35379 [==============================] - 3s 89us/sample - loss: 22.1447 - mae: 4000678.0000 - mse: 47054697005056.0000\n",
      "Epoch 8/10\n",
      "35379/35379 [==============================] - 3s 90us/sample - loss: 22.1293 - mae: 4018958.7500 - mse: 47771394506752.0000\n",
      "Epoch 9/10\n",
      "35379/35379 [==============================] - 3s 91us/sample - loss: 22.0359 - mae: 3962714.5000 - mse: 46015168118784.0000\n",
      "Epoch 10/10\n",
      "35379/35379 [==============================] - 3s 89us/sample - loss: 22.0053 - mae: 3968407.2500 - mse: 46848169476096.0000\n"
     ]
    }
   ],
   "source": [
    "stack_.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = stack_.predict(val)\n",
    "val['취급액'] = y_pred.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val.to_excel('NS_shop_예측결과.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val.취급액"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         810204.25\n",
       "1        2302592.75\n",
       "2        3262947.25\n",
       "3       16053125.00\n",
       "4       27957666.00\n",
       "           ...     \n",
       "2711    27309784.00\n",
       "2712    26311884.00\n",
       "2713    27387650.00\n",
       "2714     9236733.00\n",
       "2715    12256555.00\n",
       "Name: 취급액, Length: 2716, dtype: float32"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.취급액"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Rpt1gcg6dfkr",
    "Zn_2qqsidCtA",
    "IEkKoixnMEil",
    "_ctJVjcEfZgZ",
    "VEQ-GsooxYwD"
   ],
   "name": "2019_01_06_으로_2019_12_예측.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
